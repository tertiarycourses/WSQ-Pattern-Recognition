{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NICF-Pattern Recognition with Deep Learning-v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jE7Rj815AXks",
        "3eFpPIeZAabY",
        "N49NrPlcAddg",
        "hoC6dbd2bRKA",
        "jPXFAwUl1b5V",
        "WgQGI9_41fSJ",
        "uY6tbfDe1j3k",
        "oD3qK9B4liVT",
        "jEpIw2V0lmGF",
        "TO3WCmo2nB-Q",
        "3H1vHLHUmUId",
        "vNCS7L2amtYn",
        "av71E0Qcnwon",
        "lkEPDE4CrSsf",
        "FAALUD0-rmfJ",
        "SbWPTnTarthk",
        "itVuzyJZrzVR",
        "D6mpaNGixeDu",
        "YRck3uIwyeLo",
        "6naCWJHxygNk",
        "u4eKE0nEyxfk",
        "kMaVg1zTKCIG",
        "pa5s4rd3IpNy",
        "LUAaCFgMI1BF",
        "BR_NW9NRI3-t",
        "1sH7Cj5WKqoI",
        "3KA37_sbJHx2",
        "QrlPLfRA65Td",
        "TpKv4VWeZWuR",
        "lA4waja1-oM5",
        "_JS9mnQOAyID",
        "njdRT2vKMXjl",
        "G_aEYm4PVptX",
        "AliO7-3ZVY0R",
        "LbBe5fqIVcdS",
        "TRJT2KYRVlyB",
        "oftG5ka_YMyS",
        "CEmqPrAWa75W",
        "6tZ-97-pcFIW",
        "dm-q7PEUcqbM",
        "RTcnxwuMdWST",
        "5K0jWGjHQCk4",
        "FhDR8jvnS1Fl",
        "Xt8tuJzrOCUK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I47TcT30ufUp",
        "colab_type": "text"
      },
      "source": [
        "# NICF â€“ Pattern Recognition with Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyEOuO2oByJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr7i2L08IIp5",
        "colab_type": "text"
      },
      "source": [
        "# Topic 1 Image Recognition with CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_VWhk9MJNbc",
        "colab_type": "text"
      },
      "source": [
        "## Teachable Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xwq-5tV_p77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lL5PUOB_uOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls '/content/drive/My Drive/dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcvZN4P0-3pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "# Disable scientific notation for clarity\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Load the model\n",
        "model = tensorflow.keras.models.load_model('/content/drive/My Drive/dataset/keras_model.h5')\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "# Replace this with the path to your image\n",
        "image = Image.open('/content/drive/My Drive/dataset/test_photo.jpg')\n",
        "\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "\n",
        "# display the resized image\n",
        "image.show()\n",
        "\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2p2W2CEo240",
        "colab_type": "text"
      },
      "source": [
        "## Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GVgi54-2gk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD3qK9B4liVT",
        "colab_type": "text"
      },
      "source": [
        "### Import the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i02EGsya2lEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HtDXZUW2tpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50UcL1Cw2tlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWW-TrLWHUXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_cats_dir)\n",
        "print(train_dogs_dir)\n",
        "print(validation_cats_dir)\n",
        "print(validation_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwsapX6j22ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQqwvi4270h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEpIw2V0lmGF",
        "colab_type": "text"
      },
      "source": [
        "### Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtOhb7kR3AC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0uVoHIQ3DbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO3WCmo2nB-Q",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the raw images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMONiajb3N-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpOtG-O3P-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkKcszhEm-KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1vHLHUmUId",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7r_aTsV3TMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCS7L2amtYn",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG2URME73ePz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_original = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av71E0Qcnwon",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY2A6qRw3hee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_original.history['loss']\n",
        "val_loss = history_original.history['val_loss']\n",
        "acc = history_original.history['accuracy']\n",
        "val_acc = history_original.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjn8ELnOuPoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCMsOomhuYDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/dataset/cats_and_dogs_small.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZly67jTunZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/dataset/cats_and_dogs_small.h5')\n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnFtBbBinLgz",
        "colab_type": "text"
      },
      "source": [
        "### Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC5jis8VvsEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = '/content/drive/My Drive/dataset/test_cat.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VkJ4t1EwB60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csqfQGXA4yRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soNPu-2ZDc5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/dataset/test_dog.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysz9VFkkDscm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sT7qfljDuov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtPpxGzPstu0",
        "colab_type": "text"
      },
      "source": [
        "## Feature Map Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkj2LW13wPCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Extracts the outputs of the top 8 layers:\n",
        "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
        "\n",
        "# Creates a model that will return these outputs, given the model input:\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI3AjEG8wi3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This will return a list of 5 Numpy arrays:\n",
        "# one array per layer activation\n",
        "activations = activation_model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHuLYMC02C63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_layer_activation = activations[0]\n",
        "print(first_layer_activation.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3bmVbgY3pux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "i = 30 # Try i from 0 to 51\n",
        "plt.matshow(first_layer_activation[0, :, :, i], cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymKYpQ8455wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_names = []\n",
        "for layer in model.layers[:8]:\n",
        "    layer_names.append(layer.name)\n",
        "\n",
        "images_per_row = 16\n",
        "\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    # This is the number of features in the feature map\n",
        "    n_features = layer_activation.shape[-1]\n",
        "\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # We will tile the activation channels in this matrix\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    # We'll tile each filter into this big horizontal grid\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # Post-process the feature to make it visually palatable\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    # Display the grid\n",
        "    scale = 1. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                        scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98wWam50o8Vx",
        "colab_type": "text"
      },
      "source": [
        "## Multiple Categories Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCNstbNxIvJF",
        "colab_type": "text"
      },
      "source": [
        "### Access the data to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWAewVQRpHUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq3UW9SleU36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IohVMD8VhvsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls '/content/drive/My Drive/dataset/transport'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLEj-Bzqkl0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/drive/My Drive/dataset/transport\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwvTrMrjXntA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuAmMj2zXsGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_car_dir = os.path.join(train_dir, 'car')  # directory with our training car pictures\n",
        "train_bike_dir = os.path.join(train_dir, 'bike')  # directory with our training bike pictures\n",
        "train_plane_dir = os.path.join(train_dir, 'plane')  # directory with our training bike pictures\n",
        "validation_car_dir = os.path.join(validation_dir, 'car')  # directory with our validation car pictures\n",
        "validation_bike_dir = os.path.join(validation_dir, 'bike')  # directory with our validation bike pictures\n",
        "validation_plane_dir = os.path.join(validation_dir, 'plane')  # directory with our validation bus pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qygKKy3cYM3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_car_dir)\n",
        "print(train_bike_dir)\n",
        "print(train_plane_dir)\n",
        "print(validation_car_dir)\n",
        "print(validation_bike_dir)\n",
        "print(validation_plane_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeD1zJ7xYnTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_car_tr = len(os.listdir(train_car_dir))\n",
        "num_bike_tr = len(os.listdir(train_bike_dir))\n",
        "num_plane_tr = len(os.listdir(train_plane_dir))\n",
        "\n",
        "num_car_val = len(os.listdir(validation_car_dir))\n",
        "num_bike_val = len(os.listdir(validation_bike_dir))\n",
        "num_plane_val = len(os.listdir(validation_plane_dir))\n",
        "\n",
        "total_train = num_car_tr + num_bike_tr + num_plane_tr\n",
        "total_val = num_car_val + num_bike_val + num_plane_val\n",
        "\n",
        "print('total training car images:', num_car_tr)\n",
        "print('total training bike images:', num_bike_tr)\n",
        "print('total training bus images:', num_plane_tr)\n",
        "\n",
        "print('total validation car images:', num_car_val)\n",
        "print('total validation bike images:', num_bike_val)\n",
        "print('total validation plane images:', num_plane_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iILAEv3tk3wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6lCAA6WI1jV",
        "colab_type": "text"
      },
      "source": [
        "### Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKXdFbaOk9Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "desF72rqlPkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size, \n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWb25-Yllhg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snSwkbSApodF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFUe6yDOlrYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA8gIBVMI4R9",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWL-q-j7lzvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShXj81TYI9cB",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDWSrk_cl4V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGBJ7yxU_S2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiACGeIkBPSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = '/content/drive/My Drive/dataset/test_car.jpeg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBBJVqBtBV7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U3MXvQcBhxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYyS5ZZdB4Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/dataset/test_bike.jpeg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wFiAxPqB7Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSnuWeYFB-ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6-W1s7NC-w6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/dataset/test_plane.jpeg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CXIMijnDBq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhoEevuNDDOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgViJ2IO1ndb",
        "colab_type": "text"
      },
      "source": [
        "# Topic 2 Methods to Solve Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkEPDE4CrSsf",
        "colab_type": "text"
      },
      "source": [
        "### Weight Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8cN_q1kEIlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBR-_z35EQK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LhzkXoiEUGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIh-q73cEb21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_cats_dir)\n",
        "print(train_dogs_dir)\n",
        "print(validation_cats_dir)\n",
        "print(validation_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EwiQCysEibC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmhSK6nwEnWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWxfddGcErbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvNaLl0aEsa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIe71UZ6Ex52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZju7TMsFURb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_l2 = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNeqV73JGoTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_l2.history['loss']\n",
        "val_loss = history_l2.history['val_loss']\n",
        "acc = history_l2.history['accuracy']\n",
        "val_acc = history_l2.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2-O3eX-H5SP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l1(0.001), input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Hm9YwqH_LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_l1 = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STgaNNW7IL24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_l1.history['loss']\n",
        "val_loss = history_l1.history['val_loss']\n",
        "acc = history_l1.history['accuracy']\n",
        "val_acc = history_l1.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWaQiuA-Lffs",
        "colab_type": "text"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkPvPWENLwqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJsEedg5MBr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_dropout = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrp6D1LuMD7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_dropout.history['loss']\n",
        "val_loss = history_dropout.history['val_loss']\n",
        "acc = history_dropout.history['accuracy']\n",
        "val_acc = history_dropout.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6mpaNGixeDu",
        "colab_type": "text"
      },
      "source": [
        "### Data Augumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkyUlE-g4KN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBNK6kzB4Nrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMtG5LNYOMO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSY-00oU4SCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRck3uIwyeLo",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QU9CT1u4WYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6naCWJHxygNk",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWN9-NfR4Z5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_augmentation = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4eKE0nEyxfk",
        "colab_type": "text"
      },
      "source": [
        "### Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVpfC2X4erj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_augumentation.history['loss']\n",
        "val_loss = history_augumentation.history['val_loss']\n",
        "acc = history_augumentation.history['accuracy']\n",
        "val_acc = history_augumentation.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPNM818eRSXh",
        "colab_type": "text"
      },
      "source": [
        "### Comparison of Methods "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO9pQyVMRRg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss_original = history_original.history['val_loss']\n",
        "val_loss_l1 = history_l1.history['val_loss']\n",
        "val_loss_l2 = history_l2.history['val_loss']\n",
        "val_loss_dropout = history_dropout.history['val_loss']\n",
        "val_loss_augmentation = history_augumentation.history['val_loss']\n",
        "\n",
        "val_acc_original = history_original.history['val_accuacy']\n",
        "val_acc_l1 = history_l1.history['val_accuacy']\n",
        "val_acc_l2 = history_l2.history['val_accuacy']\n",
        "val_acc_dropout = history_dropout.history['val_accuacy']\n",
        "val_acc_augmentation = history_augumentation.history['val_accuacy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss_original,label='Original val_loss')\n",
        "plt.plot(epoch,val_loss_l1,label='L1 Regularization val_loss')\n",
        "plt.plot(epoch,val_loss_l2,label='L2 Regularization val_loss')\n",
        "plt.plot(epoch,val_loss_droput,label='Dropout val_loss')\n",
        "plt.plot(epoch,val_loss_augmentation,label='Data Augmentation val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc_original,label='Original val_acc')\n",
        "plt.plot(epoch,val_acc_l1,label='L1 Regularization val_acc')\n",
        "plt.plot(epoch,val_acc_l2,label='L2 Regularization val_acc')\n",
        "plt.plot(epoch,val_acc_droput,label='Dropout val_acc')\n",
        "plt.plot(epoch,val_acc_augmentation,label='Data Augmentation val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMaVg1zTKCIG",
        "colab_type": "text"
      },
      "source": [
        "## Activity: Dropout and Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkCujaTvKBAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLW6dO7GLStl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/drive/My Drive/dataset/transport\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIw08yAA7f5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhwnLCbb7qs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_car_dir = os.path.join(train_dir, 'car')  # directory with our training car pictures\n",
        "train_bike_dir = os.path.join(train_dir, 'bike')  # directory with our training bike pictures\n",
        "train_plane_dir = os.path.join(train_dir, 'plane')  # directory with our training bike pictures\n",
        "validation_car_dir = os.path.join(validation_dir, 'car')  # directory with our validation car pictures\n",
        "validation_bike_dir = os.path.join(validation_dir, 'bike')  # directory with our validation bike pictures\n",
        "validation_plane_dir = os.path.join(validation_dir, 'plane')  # directory with our validation bus pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Vtvavt7xUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_car_tr = len(os.listdir(train_car_dir))\n",
        "num_bike_tr = len(os.listdir(train_bike_dir))\n",
        "num_plane_tr = len(os.listdir(train_plane_dir))\n",
        "\n",
        "num_car_val = len(os.listdir(validation_car_dir))\n",
        "num_bike_val = len(os.listdir(validation_bike_dir))\n",
        "num_plane_val = len(os.listdir(validation_plane_dir))\n",
        "\n",
        "total_train = num_car_tr + num_bike_tr + num_plane_tr\n",
        "total_val = num_car_val + num_bike_val + num_plane_val\n",
        "\n",
        "print('total training car images:', num_car_tr)\n",
        "print('total training bike images:', num_bike_tr)\n",
        "print('total training bus images:', num_plane_tr)\n",
        "\n",
        "print('total validation car images:', num_car_val)\n",
        "print('total validation bike images:', num_bike_val)\n",
        "print('total validation plane images:', num_plane_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrV5JzSk78nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPhfDE1l8ENh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB2-2ZnP8T9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdNXhQ0y8ZAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyz1GLPZ8g8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLQc_6Q98mgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn9Lctpx8rQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history= model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nOtnEl5-0Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8M-eZxlU1Ql",
        "colab_type": "text"
      },
      "source": [
        "# Topic 3 Functional Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjzGIe8RcUDU",
        "colab_type": "text"
      },
      "source": [
        "## Layer as Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_H2NX6Lb0mC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIfkfaufbfJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXMDfqSKbqML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-9koZudb6X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIqHY2_wb9za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFI948QQcAZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn3x3tYCcDnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1My_b-RucG3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhDM8qHIcQWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# model = Sequential([\n",
        "#     Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "#     MaxPooling2D(),\n",
        "#     Conv2D(64, 3, padding='same', activation='relu'),\n",
        "#     MaxPooling2D(),\n",
        "#     Conv2D(128, 3, padding='same', activation='relu'),\n",
        "#     MaxPooling2D(),\n",
        "#     Conv2D(128, 3, padding='same', activation='relu'),\n",
        "#     MaxPooling2D(),\n",
        "#     Flatten(),\n",
        "#     Dense(512, activation='relu'),\n",
        "#     Dense(2, activation='softmax')\n",
        "# ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njf-bL8HcfWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH,3))\n",
        "x = Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "outputs = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjiVw0bmeDyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrwT5BTYeuRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sH7Cj5WKqoI",
        "colab_type": "text"
      },
      "source": [
        "### Ex: Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC3WniIUU44L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L33hhQ0fgESM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/drive/My Drive/dataset/transport\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIikWWgIgMKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmby2u05gSVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_car_dir = os.path.join(train_dir, 'car')  # directory with our training car pictures\n",
        "train_bike_dir = os.path.join(train_dir, 'bike')  # directory with our training bike pictures\n",
        "train_plane_dir = os.path.join(train_dir, 'plane')  # directory with our training bike pictures\n",
        "validation_car_dir = os.path.join(validation_dir, 'car')  # directory with our validation car pictures\n",
        "validation_bike_dir = os.path.join(validation_dir, 'bike')  # directory with our validation bike pictures\n",
        "validation_plane_dir = os.path.join(validation_dir, 'plane')  # directory with our validation bus pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7yyGamQgZot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SpQxJ73ggKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6GnOx_mhzB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-VDJbNbgwvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT4u4jVNhD-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wGHJ3FMhPWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrlPLfRA65Td",
        "colab_type": "text"
      },
      "source": [
        "###Ensembling with Nested Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKjxR7nr64Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "  inputs = keras.Input(shape=(128,))\n",
        "  outputs = layers.Dense(1, activation='sigmoid')(inputs)\n",
        "  return keras.Model(inputs, outputs)\n",
        "\n",
        "model1 = get_model()\n",
        "model2 = get_model()\n",
        "model3 = get_model()\n",
        "\n",
        "inputs = keras.Input(shape=(128,))\n",
        "y1 = model1(inputs)\n",
        "y2 = model2(inputs)\n",
        "y3 = model3(inputs)\n",
        "outputs = layers.average([y1, y2, y3])\n",
        "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ureVFSbwIj3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(ensemble_model, 'model.png')\n",
        "# keras.utils.plot_model(model, 'model.png', show_shapes=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSeutphmZWDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers \n",
        "encoder_input = keras.Input(shape=(28, 28, 1), name='original_img')\n",
        "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
        "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "decoder_input = keras.Input(shape=(16,), name='encoded_img')\n",
        "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
        "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
        "\n",
        "decoder = keras.Model(decoder_input, decoder_output, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "autoencoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
        "encoded_img = encoder(autoencoder_input)\n",
        "decoded_img = decoder(encoded_img)\n",
        "autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2aDe2yOJ_dX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(autoencoder, 'model.png')\n",
        "# keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JS9mnQOAyID",
        "colab_type": "text"
      },
      "source": [
        "### Multiple Inputs and Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbI8q4kcAd55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tags = 12  # Number of unique issue tags\n",
        "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
        "num_departments = 4  # Number of departments for predictions\n",
        "\n",
        "title_input = keras.Input(shape=(None,), name='title')  # Variable-length sequence of ints\n",
        "body_input = keras.Input(shape=(None,), name='body')  # Variable-length sequence of ints\n",
        "tags_input = keras.Input(shape=(num_tags,), name='tags')  # Binary vectors of size `num_tags`\n",
        "\n",
        "# Embed each word in the title into a 64-dimensional vector\n",
        "title_features = layers.Embedding(num_words, 64)(title_input)\n",
        "# Embed each word in the text into a 64-dimensional vector\n",
        "body_features = layers.Embedding(num_words, 64)(body_input)\n",
        "\n",
        "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
        "title_features = layers.LSTM(128)(title_features)\n",
        "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
        "body_features = layers.LSTM(32)(body_features)\n",
        "\n",
        "# Merge all available features into a single large vector via concatenation\n",
        "x = layers.concatenate([title_features, body_features, tags_input])\n",
        "\n",
        "# Stick a logistic regression for priority prediction on top of the features\n",
        "priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x)\n",
        "# Stick a department classifier on top of the features\n",
        "department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x)\n",
        "\n",
        "# Instantiate an end-to-end model predicting both priority and department\n",
        "model = keras.Model(inputs=[title_input, body_input, tags_input],\n",
        "                    outputs=[priority_pred, department_pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u8nLBvYAgjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njdRT2vKMXjl",
        "colab_type": "text"
      },
      "source": [
        "## Ex: Funcational API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWWaseitMMrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "inputs = Input(shape=(32,32,3))\n",
        "\n",
        "x = Conv2D(16,(3,3),activation='relu',padding='same')(inputs)\n",
        "x = Conv2D(32,(3,3),activation='relu',padding='same')(x)\n",
        "x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n",
        "y1 = MaxPooling2D()(x)\n",
        "\n",
        "x = Conv2D(32,(3,3),activation='relu',padding='same')(inputs)\n",
        "x = Conv2D(64,(3,3),activation='relu',padding='same')(x)\n",
        "y2 = MaxPooling2D()(x)\n",
        "\n",
        "y = concatenate([y1,y2])\n",
        "y = Flatten()(y)\n",
        "y = Dense(128,activation='relu')(y)\n",
        "outputs = Dense(10,activation='softmax')(y)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "model = keras.Model(inputs, outputs, name='dual_cnn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu4U1MieNOhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras.utils.plot_model(model, 'model.png')\n",
        "keras.utils.plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeWq_7zY6oh",
        "colab_type": "text"
      },
      "source": [
        "# Topic 4 Transfer Learning for Small Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_aEYm4PVptX",
        "colab_type": "text"
      },
      "source": [
        "## Feature Extraction & Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6b5TlezSh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow. keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5oFy8mPzroV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(150, 150, 3)) \n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(512,activation='relu')(x) \n",
        "preds=Dense(2,activation='softmax')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_SuYmC4k6dI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Uf1n7ul76f",
        "colab_type": "text"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eMSbERplvws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvxkgU8Jl_5T",
        "colab_type": "text"
      },
      "source": [
        "### Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0G65Lqr0M1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HTmMZdOkijV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtBKV-RAkje1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkYtfpGZkn_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPisPFStku2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBrPCbT01fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLg258YE09am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr_nO92c1ZR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmbjR6ar2Fdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history= model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JAVJ6-Ym6wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliO7-3ZVY0R",
        "colab_type": "text"
      },
      "source": [
        "#### Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_HxRBW0aGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = '/content/drive/My Drive/dataset/test_cat.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h26GlSSs6Ima",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtEBS8n76MlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG5RKBIT7isb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/dataset/test_dog.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raRlK-t66dOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hGOKuAB6gQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz3J0aNwurpH",
        "colab_type": "text"
      },
      "source": [
        "## Ex: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aKz3mPpmRj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnbzU1Czu5Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/drive/My Drive/dataset/transport\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbzK7o6bvBKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMnmd1nQvFR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_car_dir = os.path.join(train_dir, 'car')  # directory with our training car pictures\n",
        "train_bike_dir = os.path.join(train_dir, 'bike')  # directory with our training bike pictures\n",
        "train_plane_dir = os.path.join(train_dir, 'plane')  # directory with our training bike pictures\n",
        "validation_car_dir = os.path.join(validation_dir, 'car')  # directory with our validation car pictures\n",
        "validation_bike_dir = os.path.join(validation_dir, 'bike')  # directory with our validation bike pictures\n",
        "validation_plane_dir = os.path.join(validation_dir, 'plane')  # directory with our validation bus pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw30hBYavIvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_car_tr = len(os.listdir(train_car_dir))\n",
        "num_bike_tr = len(os.listdir(train_bike_dir))\n",
        "num_plane_tr = len(os.listdir(train_plane_dir))\n",
        "\n",
        "num_car_val = len(os.listdir(validation_car_dir))\n",
        "num_bike_val = len(os.listdir(validation_bike_dir))\n",
        "num_plane_val = len(os.listdir(validation_plane_dir))\n",
        "\n",
        "total_train = num_car_tr + num_bike_tr + num_plane_tr\n",
        "total_val = num_car_val + num_bike_val + num_plane_val\n",
        "\n",
        "print('total training car images:', num_car_tr)\n",
        "print('total training bike images:', num_bike_tr)\n",
        "print('total training bus images:', num_plane_tr)\n",
        "\n",
        "print('total validation car images:', num_car_val)\n",
        "print('total validation bike images:', num_bike_val)\n",
        "print('total validation plane images:', num_plane_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gYSJX5NvMc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwv5PLNqvQxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI68DSXuvRWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq6_PpsvvhcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow. keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4aDUH0kvoZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(150, 150, 3)) \n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(512,activation='relu')(x) \n",
        "preds=Dense(3,activation='softmax')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQ00Y_cvsjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp9rtyVNv3hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_jwxSBk2XaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLlwee1LY0CA",
        "colab_type": "text"
      },
      "source": [
        "# Topic 5 Text Classification with RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oftG5ka_YMyS",
        "colab_type": "text"
      },
      "source": [
        "## Text Classifcaiton With RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEmqPrAWa75W",
        "colab_type": "text"
      },
      "source": [
        "### Load the IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6eJ1XvJYREL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 10000  # number of words to consider as features\n",
        "maxlen = 500  # cut texts after this number of words (among top max_features most common words)\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('input_train shape:', x_train.shape)\n",
        "print('input_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tZ-97-pcFIW",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s62nbYQoY5Bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow. keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm-q7PEUcqbM",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8MPZorXZFhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=15, batch_size=128,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTcnxwuMdWST",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwp6F2TQZNN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_YRPLVw3hrM",
        "colab_type": "text"
      },
      "source": [
        "### Add Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvYN5Q0E4TGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow. keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(32,dropout=0.1,recurrent_dropout=0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXa0k088X4CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=15, batch_size=128,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST_raSIF3gGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToVmQrTX4fdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=15, batch_size=128,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K0jWGjHQCk4",
        "colab_type": "text"
      },
      "source": [
        "## Time Series Prediction With RNN\n",
        "- Stock prices are downloaded from finance.yahoo.com. Disneyland (DIS) Stock Price CSV file.\n",
        "- Closed value (column[5]) is used in the network, LSTM Code\n",
        "Values are normalized in range (0,1).\n",
        "- Datasets are splitted into train and test sets, 50% test data, 50% training data.\n",
        "Keras-Tensorflow is used for implementation.\n",
        "- LSTM network consists of 25 hidden neurons, and 1 output layer (1 dense layer).\n",
        "- LSTM network features input: 1 layer, output: 1 layer , hidden: 25 neurons, optimizer:adam, dropout:0.1, timestep:240, batchsize:240, epochs:1000 (features can be further optimized).\n",
        "- Output files: lstm_results (consists of prediction and actual values), plot file (actual and prediction values)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ9uPy9K5tYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "import time #helper libraries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV0teW8pP9LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkNSPOVw34iU",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG-tQnZw3qOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_file=\"/content/drive/My Drive/dataset/DIS.csv\"\n",
        "\n",
        "# load the dataset\n",
        "df = read_csv(input_file, header=None, index_col=None, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UEPmiSV58bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA2ioj7k4BVC",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLMSY3sJ6Brd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take close price column[5]\n",
        "all_y = df[5].values\n",
        "dataset=all_y.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SB_eP2i6Diw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F20CLAFp7iLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nEpcIUV38RJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into train and test sets, 50% test data, 50% training data\n",
        "train_size = int(len(dataset) * 0.5)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo0hlTaV4xNG",
        "colab_type": "text"
      },
      "source": [
        "### Reshape data for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sevHuAQ34suu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcgMHJU77quv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape into X=t and Y=t+1, timestep 240\n",
        "look_back = 240\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skmggj_d8byW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSNnuJMy8hpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRMipmp98nqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUOF6Va08p7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjd9Qw3k8ZTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCTJlDbH9bOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zpj2qBs9ejB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFGJile8454L",
        "colab_type": "text"
      },
      "source": [
        "### Build the RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWwR9Wy55Ahc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create and fit the LSTM network, optimizer=adam, 25 neurons\n",
        "model = Sequential()\n",
        "model.add(LSTM(25, activation='relu',input_shape=(1, look_back)))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7PxwVIp5ExW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=1000, batch_size=240)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3bQaCAl5P23",
        "colab_type": "text"
      },
      "source": [
        "### Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKQObsyW5Noe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMx5o_jN80s_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "testPredict = scaler.inverse_transform(testPredict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RuqK5JK5Vg3",
        "colab_type": "text"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HY0BoK688lI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(dataset)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b9Ays6j2Qxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(dataset))\n",
        "plt.plot(trainPredictPlot)\n",
        "\n",
        "# plot the actual price, prediction in test data=red line, actual price=blue line\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhDR8jvnS1Fl",
        "colab_type": "text"
      },
      "source": [
        "## Stack RNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPAGD1EMSp31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(25, input_shape=(1, look_back),return_sequences=True))\n",
        "model.add(LSTM(25,activation='relu'))\n",
        "model.add(Dense(1,activation='linear'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9tdU-srS30W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=1000, batch_size=240)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWl1iR1uS7Fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A40463ju-BVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "testPredict = scaler.inverse_transform(testPredict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRxZxKc4-HYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(dataset)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j24xTTI-KkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(dataset))\n",
        "plt.plot(trainPredictPlot)\n",
        "\n",
        "# plot the actual price, prediction in test data=red line, actual price=blue line\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt8tuJzrOCUK",
        "colab_type": "text"
      },
      "source": [
        "## Bidirectional RNN Architecuture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Veyr1wElHTqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(25, input_shape=(1, look_back))))\n",
        "model.add(Dense(1,activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibySHAOoIAvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=1000, batch_size=240)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1OccE5KN7aS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mukukmi--szX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "testPredict = scaler.inverse_transform(testPredict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIM8PU0d-xdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(dataset)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAsKGJD8-1-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(dataset))\n",
        "plt.plot(trainPredictPlot)\n",
        "\n",
        "# plot the actual price, prediction in test data=red line, actual price=blue line\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znm2blWSXi7w",
        "colab_type": "text"
      },
      "source": [
        "## Ex: RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUddIpsjzQr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 10000  # number of words to consider as features\n",
        "maxlen = 500  # cut texts after this number of words (among top max_features most common words)\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('input_train shape:', x_train.shape)\n",
        "print('input_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a99DmjUPXk2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow. keras.layers import LSTM, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1zeHH3qXrx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=15, batch_size=128,validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jHTg6-LXxno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}